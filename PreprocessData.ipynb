{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocessData.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6vcRR0NjIWC"
      },
      "source": [
        "Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnNJisgWjMII"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nm2YUpXjOjC"
      },
      "source": [
        "Read the dataset provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZwa7Y24jTsX"
      },
      "source": [
        "read_dataset = pd.read_csv(\"/content/drive/My Drive/ML/q2_dataset.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsPOzi5cjdN0"
      },
      "source": [
        "Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K81eI56jkDV"
      },
      "source": [
        "read_dataset['Date'] =pd.to_datetime(read_dataset.Date)\n",
        "read_dataset=read_dataset.sort_values('Date')\n",
        "\n",
        "dataset = read_dataset.iloc[:, 2:6].values\n",
        "\n",
        "data=np.empty((1256,13),dtype=float)    #numpy array of index, followed by 12 features\n",
        "target=np.empty((1256),dtype=float)     #numpy array of target values as open values for 4th day\n",
        "\n",
        "#creating index \"ind\" for data to later sort data by date for plotting\n",
        "ind=1\n",
        "\n",
        "#converting the data into a set of data and target arrays\n",
        "for i in range(0,data.shape[0]):\n",
        "    row=[ind]\n",
        "    target[i]=dataset[i+3][1]\n",
        "    for k in range(3):\n",
        "        for j in range(4):\n",
        "            row.append(dataset[k+i][j])\n",
        "    data[i]=row\n",
        "    ind+=1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwP8loAIjnVH"
      },
      "source": [
        "Split data into 70% train and 30% test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8NBPda9jx6l",
        "outputId": "e3c77103-46ad-44bf-e197-72593988a616"
      },
      "source": [
        "data_train,data_test,target_train ,target_test= train_test_split(data,target,test_size=0.30, shuffle=True)\n",
        "print(data_train.shape, data_test.shape, target_train.shape,target_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(879, 13) (377, 13) (879,) (377,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSWaWebWj0Li"
      },
      "source": [
        "Creating train and test numpy arrays having 14 values in each row: 1 index + 12 features + 1 target value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esnoCYAqj8Pe",
        "outputId": "af89ef3c-7226-4035-df83-967ab8c00f97"
      },
      "source": [
        "save_train_data=np.empty((data_train.shape[0],14))\n",
        "save_test_data=np.empty((data_test.shape[0],14))\n",
        "\n",
        "for i in range (save_train_data.shape[0]):\n",
        "    row=data_train[i]\n",
        "    row=np.append(row,target_train[i])\n",
        "    save_train_data[i]=row\n",
        "print(\"train shape\",save_train_data.shape)\n",
        "\n",
        "for i in range (save_test_data.shape[0]):\n",
        "    row=data_test[i]\n",
        "    row=np.append(row,target_test[i])\n",
        "    save_test_data[i]=row\n",
        "print(\"test shape\",save_test_data.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape (879, 14)\n",
            "test shape (377, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x19N0WJkBFT"
      },
      "source": [
        "Saving the data in .csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcNfOmNbkDha"
      },
      "source": [
        "np.savetxt('/content/drive/My Drive/ML/train_data_RNN.csv', [p for p in (save_train_data)], delimiter=',', fmt='%s')\n",
        "np.savetxt('/content/drive/My Drive/ML/test_data_RNN.csv', [p for p in (save_test_data)], delimiter=',', fmt='%s')"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}